{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'setup.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# import urllib.request\n",
    "\n",
    "# url = 'https://shapenet.cs.stanford.edu/ericyi/shapenetcore_partanno_v0.zip'\n",
    "# urllib.request.urlretrieve(url, 'data.zip')\n",
    "# from zipfile import ZipFile\n",
    "# with ZipFile('data.zip', 'r') as zipObj:\n",
    "#    # Extract all the contents of zip file in different directory\n",
    "#    zipObj.extractall('data')\n",
    "    \n",
    "# url = 'https://github.com/chrdiller/pyTorchChamferDistance/archive/master.zip'\n",
    "# urllib.request.urlretrieve(url, 'chamfer.zip')\n",
    "# with ZipFile('chamfer.zip', 'r') as zipObj:\n",
    "#    # Extract all the contents of zip file in different directory\n",
    "#    zipObj.extractall('')\n",
    "    \n",
    "# url = 'https://github.com/meder411/PyTorch-EMDLoss/archive/master.zip'\n",
    "# urllib.request.urlretrieve(url, 'emd.zip')\n",
    "# with ZipFile('emd.zip', 'r') as zipObj:\n",
    "#    # Extract all the contents of zip file in different directory\n",
    "#    zipObj.extractall('')\n",
    "    \n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs have been detected:1\n",
      "Random Seed:  335\n",
      "number of training data:15990\n",
      "number of testing data:1785\n",
      "model building...\n",
      "training mode ------------------\n",
      "epoch:0\n",
      "1000\n",
      "training loss is:0.893593966960907\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-592d9ec3ed99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of GPUs have been detected:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m#with torch.cuda.device(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-592d9ec3ed99>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "from datasets import PartDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda as cuda\n",
    "from pic2points_model import pic2points\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from chamfer_distance import ChamferDistance\n",
    "#from emd import EMDLoss\n",
    "\n",
    "#dist =  EMDLoss()\n",
    "\n",
    "chamferDist = ChamferDistance()\n",
    "\n",
    "def main():\n",
    "    manualSeed = random.randint(1, 10000) # fix seed\n",
    "    print(\"Random Seed: \", manualSeed)\n",
    "    random.seed(manualSeed)\n",
    "    torch.manual_seed(manualSeed)\n",
    "\n",
    "    dataset = PartDataset(root = 'data/PartAnnotation/', pic2point = True, npoints = 2500)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True, num_workers=8)\n",
    "    print(\"number of training data:\"+ str(len(dataset)))\n",
    "    test_dataset = PartDataset(root = 'data/PartAnnotation/', pic2point = True, train = False, npoints = 2500)\n",
    "    testdataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16,shuffle=True, num_workers=8)\n",
    "    print(\"number of testing data:\"+ str(len(test_dataset)))\n",
    "\n",
    "    # creat model\n",
    "    print(\"model building...\")\n",
    "    model = pic2points(num_points=2500)\n",
    "    model.cuda()\n",
    "\n",
    "    # load pre-existing weights\n",
    "  #  if opt.model != '':\n",
    "   #     model.load_state_dict(torch.load(opt.model))\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    num_batch = len(dataset) / 32\n",
    "\n",
    "    print('training mode ------------------')\n",
    "    for epoch in range(100):\n",
    "        print(\"epoch:\"+str(epoch))\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            print(len(dataloader))\n",
    "            im, points = data\n",
    "            im, points = Variable(im), Variable(points)\n",
    "            im, points = im.cuda(), points.cuda()\n",
    "#             print('im size = ', im.size())\n",
    "#             print('points size = ', points.size())\n",
    "            pred = model(im)\n",
    "            dist1, dist2 = chamferDist(pred, points)\n",
    "            loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "#             emd_cost = torch.sum(dist(pred.cuda().double(), points.cuda().double()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 50 is 0:\n",
    "                print(\"training loss is:\" + str(loss.item()))\n",
    "\n",
    "        loss_test = 0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            im_test, points_test = data\n",
    "            im_test, points_test = Variable(im_test), Variable(points_test)\n",
    "            im_test, points_test = im_test.cuda(), points_test.cuda()\n",
    "            pred_test = model(im_test)\n",
    "            dist1, dist2 = chamferDist(pred_test, points_test)\n",
    "            loss_test = (torch.mean(dist1)) + (torch.mean(dist2))\n",
    "#             emd_test = torch.sum(dist(pred_test.cuda().double(), points_test.cuda().double()))\n",
    "        print(\"Testing loss is:\" + str(loss_test.item()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num_cuda = cuda.device_count()\n",
    "    print(\"number of GPUs have been detected:\" + str(num_cuda))\n",
    "    #with torch.cuda.device(1):\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
